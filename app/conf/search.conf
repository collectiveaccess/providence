#
# Search configuration
#

# number of seconds to keep cached searches around
# set to 0 to disable caching
cache_timeout = 0

# Maximum number of records to buffer indexing for before
# writing out to search engine. Generally, larger numbers provide better
# performance up to a point, at the expense of memory footprint. Larger 
# values may cause issues with some engines. If you are experiencing errors while 
# indexing, excessive memory use or lost indexing trying reducing the value of 
# this setting and then reindex.
#
max_indexing_buffer_size = 5000

# -------------------
# SqlSearch plugin configuration
# -------------------

# Set to 0 if you don't want search input stemmed (ie. suffixes removed) prior to search
# The plugin uses the English Snoball stemmer (http://snowball.tartarus.org/) and can give
# poor results with non-English content. If you are cataloguing non-English material you
# will probably want to turn this off.
search_sql_search_do_stemming = 1

# -------------------
# ElasticSearch plugin configuration
# -------------------

# Set to 2 for version 2.x, 5 for 5.x, 6 for 6.x, 7 for 7.x
elasticsearch_version = 7

# Enter the elastic search base url here (without any index names)
search_elasticsearch_base_url = http://localhost:9200/

# This is the prefix of ElasticSearch indexes used by CollectiveAccess. An index will
# be create for each indexed collectiveAcccess table, named with this prefix + the table 
# name. (Eg. collectiveacces_ca_objects). You probably don't need to change this unless 
# you're using a single ElasticSearch setup for multiple CollectiveAccess instances and/or
# other applications.
search_elasticsearch_index_name = collectiveaccess

# ElasticSearch-specific ndexing buffer size. Larger values *may* improve performance
# but will use more memory.
elasticsearch_indexing_buffer_size = 250

# -------------------
# General search and indexing behavior (all plugins)
# -------------------
# Suffixes to add to searches if they conform to a listed regular expression
search_suffixes = {
#	[\\d]+\\.[0-9A-Za-z\\.]* = *
}


# Create a single index entry for all instances of a term in a field. 
#
# By default an index entry is created for each repetition of a term. The entries includes 
# locations of repeated term within the field. This location data supports "strict" phrase 
# searching, where results are only returned for records with the phrase terms present in 
# the searched-upon sequence. 
# 
# Grouping index entries for repeating values in a field may reduce the size of the search 
# index and improve performance, but will disable strict phrase searches. In their stead
# all records containing the specified search terms *anywhere* in the specified field will
# be returned. (Only supported in SqlSearch2)
#
group_index_for_repeating_terms_in_field =  0

# Stop words are common terms unlikely to selective and therefore filtered from search input 
# prior to execution of the search. Filtering stop words may reduce the size of the search
# index and improve performance. However, it may adversely affect search accuracy and 
# relevance if the stop word list contents terms significant for current content.
#
# Stop words will be applied to all cataloguing languages for which a word list is defined
# at https://github.com/voku/stop-words
use_stop_words = 0

# Regular expression defining characters to be considered whitespace when indexing using 
# the SqlSearch2 search engine plugin
whitespace_tokenizer_regex = "[\\s\"“”\\—]+"

# Regular expression defining punctuation characters to be stripped prior to indexing using
# the SqlSearch2 search engine plugin
punctuation_tokenizer_regex = "[,;:\\(\\)\{\\}\[\\]\\|\\\\\\+\\!\\&«»\\'’]+"

# Regular expression defining characters to be stripped from beginning and end only prior to indexing using
# the SqlSearch2 search engine plugin. These are characters typically used in identifier where leading
# and trailing occurrences are not significant, but interior occurrences are.
separator_tokenizer_regex = "[\\._\\-\\/]+"

# List of regular expressions that if matched cause search input to be treated "as-is" - searched without processing
# This is useful for preventing tokenization of accession numbers and other values that rely upon punctuation being
# kept intact.
asis_regexes = [
	"^[\\d]+[\\.\\-][A-Za-z0-9\\.\\-]+$",
	"[^\\.]+\\.[A-Za-z0-9]{3}$"
]

# List of regular expressions that if matched cause search input to be treated as an idno. This is useful
# for forcing text searches on apparent idno's to limit themselves to the literal idno field. It also allows
# ElasticSearch to support idno text searches with idno's that contain dashes. Without binding to a specific 
# field Elastic will treat the dashes as special characters and fail to match dash literals.
#
# You may define as many regular expression as needed here to match idno patterns. Each regular expression will be
# evaluated in term until a match is found. First level keys are table names, with an associated list of regexes. 
#
idno_regexes = {
	ca_objects = [
		"[\\d]{4}\\.[\d]{1,5}\\.[\\d]{0,5}"
	]
}

# List of regular expressions used to rewrite search expressions before execution. First level
# keys are table names, with an associated list of regexes. Each regex key is a descriptive name with an
# associated two element list. The first element is a regular expression, the second is the replacement pattern. Back references
# are supported.
#
rewrite_regexes = {
	ca_objects = {
		#remove_wildcards = [
		#	"/\\*", ""
		#]
	}
}

# By default all in-memory sorting is performed using the PHP SORT_NATURAL mode (see http://php.net/manual/en/function.sort.php)
# This is usually what is wanted, but for some languages (Eg. Spanish) it can return odd results and it may be desirable to disable it
dont_use_natural_sort = 0

# Index "before x" and "after x" date expressions as if they were circa dates
treat_before_dates_as_circa = 0
treat_after_dates_as_circa = 0

# To improve performance sorting of search results is performed in-memory for results up to a certain size.
# Larger results are sorted using the database. The threshold at which in-memory sorting
# is no longer performed can be controlled here. The setting is the maximum size of a result size to
# be sorted in memory. 
max_hits_for_in_memory_search = 1000000

# Force all search input to be treated as a stem, matching all words beginning 
# with or matching the input 
always_stem = 0

# Ignore fields full text searches? Exclusions are set by table and only apply to full text searches. Field-specific
# searches will still work.
exclude_fields_froms_search = {
#	ca_objects = {
#		ca_objects.object_id, ca_objects.hier_object_id
#	}
}

# The query parser considers "&" and "|" characters to be equivalent to logical "AND" and "OR", and requires searches
# on these characters to use a double value. Eg. to find "Martini & Rossi" the search "Martini && Rossi" must be used.
# To disable use of "&" an "|" as shorthand for logical combination and enable literal search on these characters 
# set this option.
allow_ampersands_and_pipes = 1

# Highlight search terms in results?
do_highlighting = 0

# Return matching details from search engine for each found item. Data includes fields and terms
# matched. This can be useful for search debugging, or to support specific search functionality such
# as highlighting specific object representation media annotations when searching for objects. 
#
# Returning this data incurs a performance hit, so only enable if needed.
return_search_result_description_data = 0

# Maximum number of index hits to report per item. A search time might match an item several times across multiple
# fields. To maintain performance, the number of matches per item is limited. Increase this number if display of more/all
# matches is required.
search_result_description_maximum_index_matches = 3
